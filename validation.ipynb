{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install m2w64-toolchain\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "import pymc3 as pm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def correlations():\n",
    "\n",
    "    # Load nutrition data\n",
    "    df_tesco_msoa = pd.read_csv('year_msoa_grocery.csv', encoding='utf-8', header=0)\n",
    "    df_tesco_ward = pd.read_csv('year_osward_grocery.csv', encoding='utf-8', header=0)\n",
    "    df_tesco_oslaua = pd.read_csv('year_borough_grocery.csv', encoding='utf-8', header=0)\n",
    "\n",
    "    # Load health data\n",
    "    df_child_obesity_ward = pd.read_csv('child_obesity_london_ward_2013-2014.csv', encoding='utf-8', header=0).dropna()\n",
    "    df_child_obesity_oslaua = pd.read_csv('child_obesity_london_borough_2015-2016.csv', encoding='utf-8', header=0).dropna()\n",
    "    df_adult_obesity_oslaua = pd.read_csv('london_obesity_borough_2012.csv', encoding='utf-8', header=0).dropna()\n",
    "    df_adult_obesity_hospital_oslaua = pd.read_csv('obesity_hospitalization_borough_2016.csv', encoding='utf-8',\n",
    "                                                   header=0).dropna()\n",
    "    df_diabetes_ward = pd.read_csv('diabetes_estimates_osward_2016.csv', encoding='utf-8', header=0).dropna()\n",
    "\n",
    "    outfile = open('correlations_health_outcomes.csv', 'wt', encoding='utf-8')\n",
    "    outfile.write('outcome,nutrient,r,p\\n')\n",
    "\n",
    "    food_indicators = ['energy_tot', 'energy_fat', 'energy_saturate', 'energy_sugar', 'energy_protein', 'energy_carb',\n",
    "                       'energy_fibre', 'h_nutrients_calories_norm']\n",
    "    food_indicators_labels = ['energy', 'fat', 'saturate', 'sugar', 'protein', 'carb', 'fibre', 'diversity']\n",
    "\n",
    "    # Correlation with child obesity at Ward level\n",
    "    df_join = df_tesco_ward.merge(df_child_obesity_ward, how='inner')\n",
    "    plot_labels = ['Prevalence of overweight\\nchildren (reception)', 'Prevalence of overweight\\nchildren (year 6)',\n",
    "                   'Prevalence of obese\\nchildren (reception)', 'Prevalence of obese\\nchildren (year 6)']\n",
    "    outcomes = ['prevalence_overweight_reception', 'prevalence_overweight_y6', 'prevalence_obese_reception', 'prevalence_obese_y6']\n",
    "\n",
    "    for b, lab in zip(outcomes, plot_labels):\n",
    "        correl = []\n",
    "        nutrient = []\n",
    "        for a, al in zip(food_indicators, food_indicators_labels):\n",
    "            r, p = scipy.stats.spearmanr(df_join[a], df_join[b])\n",
    "            if p < 0.05:\n",
    "                outfile.write('%s,%s,%s,%s\\n' % (b, al, r, p))\n",
    "                correl.append(r)\n",
    "                nutrient.append(al)\n",
    "\n",
    "    # Correlation with adult obesity\n",
    "    df_join = df_tesco_oslaua.merge(df_adult_obesity_oslaua, how='inner')\n",
    "    plot_labels = ['Prevalence of\\noverweight adults', 'Prevalence of\\nobese adults']\n",
    "    outcomes = ['f_overweight', 'f_obese']\n",
    "    for b, lab in zip(outcomes, plot_labels):\n",
    "        correl = []\n",
    "        nutrient = []\n",
    "        for a, al in zip(food_indicators, food_indicators_labels):\n",
    "            r, p = scipy.stats.spearmanr(df_join[a], df_join[b])\n",
    "            if p < 0.05:\n",
    "                # print(b,al,r,p)\n",
    "                outfile.write('%s,%s,%s,%s\\n' % (b, al, r, p))\n",
    "                correl.append(r)\n",
    "                nutrient.append(al)\n",
    "\n",
    "    # Correlation with diabetes estimates\n",
    "    df_join_diabetes = df_tesco_ward.merge(df_diabetes_ward, how='inner')\n",
    "    plot_labels = ['Diabetes\\nprevalence']\n",
    "    outcomes = ['estimated_diabetes_prevalence']\n",
    "    for b, lab in zip(outcomes, plot_labels):\n",
    "        correl = []\n",
    "        nutrient = []\n",
    "        for a, al in zip(food_indicators, food_indicators_labels):\n",
    "            r, p = scipy.stats.spearmanr(df_join_diabetes[a], df_join_diabetes[b])\n",
    "            if p < 0.05:\n",
    "                # print(b,al,r,p)\n",
    "                outfile.write('%s,%s,%s,%s\\n' % (b, al, r, p))\n",
    "                correl.append(r)\n",
    "                nutrient.append(al)\n",
    "\n",
    "    outfile.close()\n",
    "\n",
    "correlations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=df['h_energy_nutrients_norm'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_regression():\n",
    "    df_grocery = pd.read_csv('year_osward_grocery.csv')\n",
    "    df_grocery['female_perc'] = df_grocery.apply(lambda row: row['female'] / row['population'], axis=1)\n",
    "    df_diabetes = pd.read_csv('diabetes_estimates_osward_2016.csv', encoding='utf-8', header=0).dropna()\n",
    "    df_geo = pd.read_csv('london_pcd2geo_2015.csv', encoding='utf-8')\n",
    "    df_geo = df_geo[['osward','oslaua']]\n",
    "    df_geo = df_geo.drop_duplicates()\n",
    "\n",
    "    df = df_grocery.merge(df_diabetes, how='inner', left_on='area_id', right_on='area_id')\n",
    "    df = df.merge(df_geo, how='inner', left_on='area_id', right_on='osward')\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(df['energy_carb'], df['estimated_diabetes_prevalence'], 'bo')\n",
    "    plt.xlabel(f'energy_carb', size = 18)\n",
    "    plt.ylabel(f'estimated_diabetes_prevalence', size = 18)\n",
    "\n",
    "    X1=df['energy_carb'].values\n",
    "    X2=df['h_nutrients_calories_norm'].values\n",
    "    X3=df['avg_age'].values\n",
    "    X4=df['female_perc'].values\n",
    "    X5=df['num_transactions'].values\n",
    "    X6=df['people_per_sq_km'].values\n",
    "\n",
    "    X5 = np.array([np.log2(x) for x in X5])\n",
    "    X6 = np.array([np.log2(x) for x in X6])\n",
    "\n",
    "    Y=df['estimated_diabetes_prevalence'].values\n",
    "\n",
    "    oslaua2index = {}\n",
    "    i=0\n",
    "    for v in df['oslaua'].values:\n",
    "        if v not in oslaua2index:\n",
    "            oslaua2index[v]=i\n",
    "            i += 1\n",
    "\n",
    "    df['oslaua_idx'] = df.apply(lambda row : oslaua2index[row['oslaua']], axis=1)\n",
    "        \n",
    "    n_oslauas = n_counties = len(df['oslaua_idx'].unique())\n",
    "    oslaua_idx = df['oslaua_idx'].values\n",
    "\n",
    "    hierarchical_model = pm.Model()\n",
    "    with hierarchical_model:\n",
    "        # Hyperpriors for group nodes\n",
    "        mu_a = pm.Normal('mu_a', mu=0., sigma=100)\n",
    "        sigma_a = pm.HalfNormal('sigma_a', 5.)\n",
    "        a = pm.Normal('a', mu=mu_a, sigma=sigma_a, shape=n_oslauas)\n",
    "        \n",
    "        mu_b1 = pm.Normal('mu_b1', mu=0., sigma=100)\n",
    "        sigma_b1 = pm.HalfNormal('sigma_b1', 5.)\n",
    "        b1 = pm.Normal('b1', mu=mu_b1, sigma=sigma_b1, shape=n_oslauas)\n",
    "        \n",
    "        mu_b2 = pm.Normal('mu_b2', mu=0., sigma=100)\n",
    "        sigma_b2 = pm.HalfNormal('sigma_b2', 5.)\n",
    "        b2 = pm.Normal('b2', mu=mu_b2, sigma=sigma_b2, shape=n_oslauas)\n",
    "        \n",
    "        mu_b3 = pm.Normal('mu_b3', mu=0., sigma=100)\n",
    "        sigma_b3 = pm.HalfNormal('sigma_b3', 5.)\n",
    "        b3 = pm.Normal('b3', mu=mu_b3, sigma=sigma_b3, shape=n_oslauas)\n",
    "        \n",
    "        mu_b4 = pm.Normal('mu_b4', mu=0., sigma=100)\n",
    "        sigma_b4 = pm.HalfNormal('sigma_b4', 5.)\n",
    "        b4 = pm.Normal('b4', mu=mu_b4, sigma=sigma_b4, shape=n_oslauas)\n",
    "        \n",
    "        mu_b5 = pm.Normal('mu_b5', mu=0., sigma=100)\n",
    "        sigma_b5 = pm.HalfNormal('sigma_b5', 5.)\n",
    "        b5 = pm.Normal('b5', mu=mu_b5, sigma=sigma_b5, shape=n_oslauas)\n",
    "        \n",
    "        mu_b6 = pm.Normal('mu_b6', mu=0., sigma=100)\n",
    "        sigma_b6 = pm.HalfNormal('sigma_b6', 5.)\n",
    "        b6 = pm.Normal('b6', mu=mu_b6, sigma=sigma_b6, shape=n_oslauas)\n",
    "        \n",
    "        # Model error\n",
    "        eps = pm.HalfCauchy('eps', 5.)\n",
    "        \n",
    "        estimate = a[oslaua_idx] + b1[oslaua_idx]*X1 + b2[oslaua_idx]*X2 + b3[oslaua_idx]*X3 + b4[oslaua_idx]*X4 + b5[oslaua_idx]*X5 + b6[oslaua_idx]*X6\n",
    "\n",
    "        # Likelihood (sampling distribution) of observations\n",
    "        likelihood = pm.Normal('likelihood', mu=estimate, sigma=eps, observed=Y)\n",
    "        \n",
    "        hierarchical_trace = pm.sample(50, tune=50, target_accept=.9)\n",
    "        \n",
    "    ppc = pm.sample_posterior_predictive(hierarchical_trace, samples=10000, model=hierarchical_model)\n",
    "    np.asarray(ppc['likelihood']).shape\n",
    "    print(az.r2_score(Y, ppc['likelihood']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-55d1ee71f8ba>:80: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  hierarchical_trace = pm.sample(50, tune=50, target_accept=.9)\n",
      "Only 50 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "C:\\Users\\gavin\\anaconda3\\envs\\python\\lib\\site-packages\\theano\\tensor\\elemwise.py:826: RuntimeWarning: divide by zero encountered in log\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "C:\\Users\\gavin\\anaconda3\\envs\\python\\lib\\site-packages\\theano\\tensor\\elemwise.py:826: RuntimeWarning: invalid value encountered in multiply\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [eps, b6, sigma_b6, mu_b6, b5, sigma_b5, mu_b5, b4, sigma_b4, mu_b4, b3, sigma_b3, mu_b3, b2, sigma_b2, mu_b2, b1, sigma_b1, mu_b1, a, sigma_a, mu_a]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='62' class='' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      15.50% [62/400 10:47<58:50 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bayesian_regression()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
